----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1          [-1, 4, 128, 128]             112
       BatchNorm2d-2          [-1, 4, 128, 128]               8
              ReLU-3          [-1, 4, 128, 128]               0
              conv-4          [-1, 4, 128, 128]               0
            Conv2d-5          [-1, 8, 128, 128]             296
       BatchNorm2d-6          [-1, 8, 128, 128]              16
              ReLU-7          [-1, 8, 128, 128]               0
              conv-8          [-1, 8, 128, 128]               0
            Conv2d-9          [-1, 8, 128, 128]             584
      BatchNorm2d-10          [-1, 8, 128, 128]              16
             ReLU-11          [-1, 8, 128, 128]               0
             conv-12          [-1, 8, 128, 128]               0
        MaxPool2d-13            [-1, 8, 64, 64]               0
             down-14            [-1, 8, 64, 64]               0
           Conv2d-15           [-1, 16, 64, 64]           1,168
      BatchNorm2d-16           [-1, 16, 64, 64]              32
             ReLU-17           [-1, 16, 64, 64]               0
             conv-18           [-1, 16, 64, 64]               0
           Conv2d-19           [-1, 16, 64, 64]           2,320
      BatchNorm2d-20           [-1, 16, 64, 64]              32
             ReLU-21           [-1, 16, 64, 64]               0
             conv-22           [-1, 16, 64, 64]               0
        MaxPool2d-23           [-1, 16, 32, 32]               0
             down-24           [-1, 16, 32, 32]               0
           Conv2d-25           [-1, 32, 32, 32]           4,640
      BatchNorm2d-26           [-1, 32, 32, 32]              64
             ReLU-27           [-1, 32, 32, 32]               0
             conv-28           [-1, 32, 32, 32]               0
           Conv2d-29           [-1, 32, 32, 32]           9,248
      BatchNorm2d-30           [-1, 32, 32, 32]              64
             ReLU-31           [-1, 32, 32, 32]               0
             conv-32           [-1, 32, 32, 32]               0
        MaxPool2d-33           [-1, 32, 16, 16]               0
             down-34           [-1, 32, 16, 16]               0
           Conv2d-35           [-1, 64, 16, 16]          18,496
      BatchNorm2d-36           [-1, 64, 16, 16]             128
             ReLU-37           [-1, 64, 16, 16]               0
             conv-38           [-1, 64, 16, 16]               0
           Conv2d-39           [-1, 64, 16, 16]          36,928
      BatchNorm2d-40           [-1, 64, 16, 16]             128
             ReLU-41           [-1, 64, 16, 16]               0
             conv-42           [-1, 64, 16, 16]               0
        MaxPool2d-43             [-1, 64, 8, 8]               0
             down-44             [-1, 64, 8, 8]               0
           Conv2d-45            [-1, 128, 8, 8]          73,856
      BatchNorm2d-46            [-1, 128, 8, 8]             256
             ReLU-47            [-1, 128, 8, 8]               0
             conv-48            [-1, 128, 8, 8]               0
           Conv2d-49            [-1, 128, 8, 8]         147,584
      BatchNorm2d-50            [-1, 128, 8, 8]             256
             ReLU-51            [-1, 128, 8, 8]               0
             conv-52            [-1, 128, 8, 8]               0
        MaxPool2d-53            [-1, 128, 4, 4]               0
             down-54            [-1, 128, 4, 4]               0
           Conv2d-55            [-1, 256, 4, 4]         295,168
      BatchNorm2d-56            [-1, 256, 4, 4]             512
             ReLU-57            [-1, 256, 4, 4]               0
             conv-58            [-1, 256, 4, 4]               0
           Conv2d-59            [-1, 256, 4, 4]         590,080
      BatchNorm2d-60            [-1, 256, 4, 4]             512
             ReLU-61            [-1, 256, 4, 4]               0
             conv-62            [-1, 256, 4, 4]               0
        MaxPool2d-63            [-1, 256, 2, 2]               0
             down-64            [-1, 256, 2, 2]               0
  ConvTranspose2d-65            [-1, 256, 4, 4]         262,400
           Conv2d-66            [-1, 128, 4, 4]         295,040
      BatchNorm2d-67            [-1, 128, 4, 4]             256
             ReLU-68            [-1, 128, 4, 4]               0
             conv-69            [-1, 128, 4, 4]               0
      BatchNorm2d-70            [-1, 128, 4, 4]             256
               up-71            [-1, 128, 4, 4]               0
  ConvTranspose2d-72            [-1, 128, 8, 8]          65,664
           Conv2d-73             [-1, 64, 8, 8]          73,792
      BatchNorm2d-74             [-1, 64, 8, 8]             128
             ReLU-75             [-1, 64, 8, 8]               0
             conv-76             [-1, 64, 8, 8]               0
      BatchNorm2d-77             [-1, 64, 8, 8]             128
               up-78             [-1, 64, 8, 8]               0
  ConvTranspose2d-79           [-1, 64, 16, 16]          16,448
           Conv2d-80           [-1, 32, 16, 16]          18,464
      BatchNorm2d-81           [-1, 32, 16, 16]              64
             ReLU-82           [-1, 32, 16, 16]               0
             conv-83           [-1, 32, 16, 16]               0
      BatchNorm2d-84           [-1, 32, 16, 16]              64
               up-85           [-1, 32, 16, 16]               0
  ConvTranspose2d-86           [-1, 32, 32, 32]           4,128
           Conv2d-87           [-1, 16, 32, 32]           4,624
      BatchNorm2d-88           [-1, 16, 32, 32]              32
             ReLU-89           [-1, 16, 32, 32]               0
             conv-90           [-1, 16, 32, 32]               0
      BatchNorm2d-91           [-1, 16, 32, 32]              32
               up-92           [-1, 16, 32, 32]               0
  ConvTranspose2d-93           [-1, 16, 64, 64]           1,040
           Conv2d-94            [-1, 8, 64, 64]           1,160
      BatchNorm2d-95            [-1, 8, 64, 64]              16
             ReLU-96            [-1, 8, 64, 64]               0
             conv-97            [-1, 8, 64, 64]               0
      BatchNorm2d-98            [-1, 8, 64, 64]              16
               up-99            [-1, 8, 64, 64]               0
 ConvTranspose2d-100          [-1, 8, 128, 128]             264
          Conv2d-101          [-1, 4, 128, 128]             292
     BatchNorm2d-102          [-1, 4, 128, 128]               8
            ReLU-103          [-1, 4, 128, 128]               0
            conv-104          [-1, 4, 128, 128]               0
     BatchNorm2d-105          [-1, 4, 128, 128]               8
              up-106          [-1, 4, 128, 128]               0
          Conv2d-107          [-1, 1, 128, 128]              37
            conv-108          [-1, 1, 128, 128]               0
================================================================
Total params: 1,926,865
Trainable params: 1,926,865
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.19
Forward/backward pass size (MB): 26.86
Params size (MB): 7.35
Estimated Total Size (MB): 34.40
----------------------------------------------------------------
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)
  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)